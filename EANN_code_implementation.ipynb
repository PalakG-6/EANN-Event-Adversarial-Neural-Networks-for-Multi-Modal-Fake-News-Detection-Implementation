{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Data Preprocessing**"
      ],
      "metadata": {
        "id": "COSV5f8ib01K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle as pickle\n",
        "import random\n",
        "from random import *\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import os\n",
        "from collections import defaultdict\n",
        "import sys, re\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import math\n",
        "from types import *\n",
        "from gensim.models import Word2Vec\n",
        "import jieba\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import os.path\n",
        "from gensim.models import Word2Vec\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn"
      ],
      "metadata": {
        "id": "EmtSzuk6Xqm9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=\"True\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJJafTMya8jT",
        "outputId": "4e7c3ce6-3f84-4876-bee7-481cae1d5670"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Preprocessing Pipeline, where where stopwords are removed and text is cleaned before further analysis or processing"
      ],
      "metadata": {
        "id": "pf2QfaFN4DKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stopwordslist(filepath = '/content/drive/MyDrive/WEIBO Dataset/EANN-KDD18-master/data/weibo/stop_words.txt'):\n",
        "    stopwords = {}\n",
        "    for line in open(filepath, 'r',encoding='utf-8').readlines():\n",
        "        # line = unicode(line, \"utf-8\").strip()\n",
        "        line = line.strip()\n",
        "        stopwords[line] = 1\n",
        "    #stopwords = [line.strip() for line in open(filepath, 'r', encoding='utf-8').readlines()]\n",
        "    return stopwords\n",
        "\n",
        "def clean_str_sst(string):\n",
        "    string = re.sub(u\"[，。 :,.；|-“”——_/nbsp+&;@、《》～（）())#O！：【】]\", \"\", string)\n",
        "    return string.strip().lower()"
      ],
      "metadata": {
        "id": "_fANgjCWXroQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read and Preprocess Image Data"
      ],
      "metadata": {
        "id": "YUPyL5Nq4hyb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_image():\n",
        "    image_list = {}\n",
        "    file_list = ['/content/drive/MyDrive/WEIBO Dataset/EANN-KDD18-master/data/weibo/nonrumor_images/', '/content/drive/MyDrive/WEIBO Dataset/EANN-KDD18-master/data/weibo/rumor_images/']\n",
        "    for path in file_list:\n",
        "        data_transforms = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "            ])\n",
        "\n",
        "        for i, filename in enumerate(os.listdir(path)):  # assuming gif\n",
        "\n",
        "            # print(filename)\n",
        "            # try:\n",
        "              im = Image.open(path + filename).convert('RGB')\n",
        "              im = data_transforms(im)\n",
        "                  #im = 1\n",
        "              image_list[filename.split('/')[-1].split(\".\")[0].lower()] = im\n",
        "            # except:\n",
        "            #     print(filename)\n",
        "    # print(\"image length \" + str(len(image_list)))\n",
        "    #print(\"image names are \" + str(image_list.keys()))\n",
        "    return image_list"
      ],
      "metadata": {
        "id": "ZPSxaWkdcHNI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write contents of 'data' into a text file"
      ],
      "metadata": {
        "id": "aZJfdt2n4xgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def write_txt(data):\n",
        "    f = open(\"/content/drive/MyDrive/WEIBO Dataset/EANN-KDD18-master/data/weibo/top_n_data.txt\", 'wb')\n",
        "    for line in data:\n",
        "        for l in line:\n",
        "            f.write(l+\"\\n\")\n",
        "        f.write(\"\\n\")\n",
        "        f.write(\"\\n\")\n",
        "    f.close()"
      ],
      "metadata": {
        "id": "AHVImSqScaoj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Organizing and preparing text and image data for further processing"
      ],
      "metadata": {
        "id": "M3UEpGce5FYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_dict = {}\n",
        "def write_data(flag, image, text_only):\n",
        "\n",
        "    def read_post(flag):\n",
        "        stop_words = stopwordslist()\n",
        "        pre_path = \"/content/drive/MyDrive/WEIBO Dataset/EANN-KDD18-master/data/weibo/tweets/\"\n",
        "        file_list = [pre_path + \"test_nonrumor.txt\", pre_path + \"test_rumor.txt\", \\\n",
        "                         pre_path + \"train_nonrumor.txt\", pre_path + \"train_rumor.txt\"]\n",
        "        if flag == \"train\":\n",
        "            id = pickle.load(open(\"/content/drive/MyDrive/WEIBO Dataset/EANN-KDD18-master/data/weibo/train_id.pickle\", 'rb'))\n",
        "        elif flag == \"validate\":\n",
        "            id = pickle.load(open(\"/content/drive/MyDrive/WEIBO Dataset/EANN-KDD18-master/data/weibo/validate_id.pickle\", 'rb'))\n",
        "        elif flag == \"test\":\n",
        "            id = pickle.load(open(\"/content/drive/MyDrive/WEIBO Dataset/EANN-KDD18-master/data/weibo/test_id.pickle\", 'rb'))\n",
        "\n",
        "\n",
        "        post_content = []\n",
        "        labels = []\n",
        "        image_ids = []\n",
        "        twitter_ids = []\n",
        "        data = []\n",
        "        column = ['post_id', 'image_id', 'original_post', 'post_text', 'label', 'event_label']\n",
        "        key = -1\n",
        "        map_id = {}\n",
        "        top_data = []\n",
        "        for k, f in enumerate(file_list):\n",
        "\n",
        "            f = open(f, 'r',  encoding='utf-8')\n",
        "            if (k + 1) % 2 == 1:\n",
        "                label = 0  ### real is 0\n",
        "            else:\n",
        "                label = 1  ####fake is 1\n",
        "\n",
        "            twitter_id = 0\n",
        "            line_data = []\n",
        "            top_line_data = []\n",
        "\n",
        "            for i, l in enumerate(f.readlines()):\n",
        "\n",
        "                if (i + 1) % 3 == 1:\n",
        "                    line_data = []\n",
        "                    twitter_id = l.split('|')[0]\n",
        "                    line_data.append(twitter_id)\n",
        "\n",
        "\n",
        "\n",
        "                if (i + 1) % 3 == 2:\n",
        "\n",
        "                    line_data.append(l.lower())\n",
        "\n",
        "                if (i + 1) % 3 == 0:\n",
        "                    l = clean_str_sst(l)\n",
        "\n",
        "                    seg_list = jieba.cut_for_search(l)\n",
        "                    new_seg_list = []\n",
        "                    for word in seg_list:\n",
        "                        if word not in stop_words:\n",
        "                            new_seg_list.append(word)\n",
        "\n",
        "                    clean_l = \" \".join(new_seg_list)\n",
        "                    if len(clean_l) > 10 and line_data[0] in id:\n",
        "                        post_content.append(l)\n",
        "                        line_data.append(l)\n",
        "                        line_data.append(clean_l)\n",
        "                        line_data.append(label)\n",
        "                        event = int(id[line_data[0]])\n",
        "                        if event not in map_id:\n",
        "                            map_id[event] = len(map_id)\n",
        "                            event = map_id[event]\n",
        "                        else:\n",
        "                            event = map_id[event]\n",
        "\n",
        "                        line_data.append(event)\n",
        "\n",
        "                        data.append(line_data)\n",
        "\n",
        "\n",
        "            f.close()\n",
        "\n",
        "        data_df = pd.DataFrame(np.array(data), columns=column)\n",
        "        write_txt(top_data)\n",
        "\n",
        "        return post_content, data_df\n",
        "\n",
        "    post_content, post = read_post(flag)\n",
        "    print(\"Original post length is \" + str(len(post_content)))\n",
        "    print(\"Original data frame is \" + str(post.shape))\n",
        "\n",
        "\n",
        "    def find_most(db):\n",
        "        maxcount = max(len(v) for v in db.values())\n",
        "        return [k for k, v in db.items() if len(v) == maxcount]\n",
        "\n",
        "    def select(train, selec_indices):\n",
        "        temp = []\n",
        "        for i in range(len(train)):\n",
        "            ele = list(train[i])\n",
        "            temp.append([ele[i] for i in selec_indices])\n",
        "            #   temp.append(np.array(train[i])[selec_indices])\n",
        "        return temp\n",
        "\n",
        "    def paired(text_only = False):\n",
        "        ordered_image = []\n",
        "        ordered_text = []\n",
        "        ordered_post = []\n",
        "        ordered_event= []\n",
        "        label = []\n",
        "        post_id = []\n",
        "        image_id_list = []\n",
        "\n",
        "        image_id = \"\"\n",
        "        for i, id in enumerate(post['post_id']):\n",
        "            for image_id in post.iloc[i]['image_id'].split('|'):\n",
        "                image_id = image_id.split(\"/\")[-1].split(\".\")[0]\n",
        "                if image_id in image:\n",
        "                    break\n",
        "\n",
        "            if text_only or image_id in image:\n",
        "                if not text_only:\n",
        "                    image_name = image_id\n",
        "                    image_id_list.append(image_name)\n",
        "                    ordered_image.append(image[image_name])\n",
        "                ordered_text.append(post.iloc[i]['original_post'])\n",
        "                ordered_post.append(post.iloc[i]['post_text'])\n",
        "                ordered_event.append(post.iloc[i]['event_label'])\n",
        "                post_id.append(id)\n",
        "\n",
        "\n",
        "                label.append(post.iloc[i]['label'])\n",
        "\n",
        "        label = np.array(label, dtype=int)\n",
        "        ordered_event = np.array(ordered_event, dtype=int)\n",
        "\n",
        "        print(\"Label number is \" + str(len(label)))\n",
        "        print(\"Rummor number is \" + str(sum(label)))\n",
        "        print(\"Non rummor is \" + str(len(label) - sum(label)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        if flag == \"test\":\n",
        "            y = np.zeros(len(ordered_post))\n",
        "        else:\n",
        "            y = []\n",
        "\n",
        "\n",
        "        data = {\"post_text\": np.array(ordered_post),\n",
        "                \"original_post\": np.array(ordered_text),\n",
        "                \"image\": ordered_image, \"social_feature\": [],\n",
        "                \"label\": np.array(label), \\\n",
        "                \"event_label\": ordered_event, \"post_id\":np.array(post_id),\n",
        "                \"image_id\":image_id_list}\n",
        "\n",
        "\n",
        "        print(\"data size is \" + str(len(data[\"post_text\"])))\n",
        "\n",
        "        return data\n",
        "\n",
        "    paired_data = paired(text_only)\n",
        "\n",
        "    print(\"paired post length is \"+str(len(paired_data[\"post_text\"])))\n",
        "    print(\"paried data has \" + str(len(paired_data)) + \" dimension\")\n",
        "    return paired_data"
      ],
      "metadata": {
        "id": "HlHSkMMocpOU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing vocabulary and text data from train, validate and test dataset"
      ],
      "metadata": {
        "id": "Jtuh7lNR5cF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Load_data(train, validate, test):\n",
        "    vocab = defaultdict(float)\n",
        "    all_text = list(train['post_text']) + list(validate['post_text'])+list(test['post_text'])\n",
        "    for sentence in all_text:\n",
        "        for word in sentence:\n",
        "            vocab[word] += 1\n",
        "    print(len(all_text),\"*************\")\n",
        "    return vocab, all_text"
      ],
      "metadata": {
        "id": "5MyxiGkOdA15"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading text data and Creating word embeddings"
      ],
      "metadata": {
        "id": "br96dcLu6Wfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 10 folds cross validation ##\n",
        "def build_data_cv(data_folder, cv=10, clean_string=True):\n",
        "    \"\"\"\n",
        "    Loads data and split into 10 folds.\n",
        "    \"\"\"\n",
        "    revs = []\n",
        "    pos_file = data_folder[0]\n",
        "    neg_file = data_folder[1]\n",
        "    vocab = defaultdict(float)\n",
        "    with open(pos_file, \"rb\") as f:\n",
        "        for line in f:\n",
        "            rev = []\n",
        "            rev.append(line.strip())\n",
        "            if clean_string:\n",
        "                orig_rev = str(\" \".join(rev))\n",
        "            else:\n",
        "                orig_rev = \" \".join(rev).lower()\n",
        "            words = set(orig_rev.split())\n",
        "            for word in words:\n",
        "                vocab[word] += 1\n",
        "            datum = {\"y\": 1,\n",
        "                     \"text\": orig_rev,\n",
        "                     \"num_words\": len(orig_rev.split()),\n",
        "                     \"split\": np.random.randint(0, cv)}\n",
        "            revs.append(datum)\n",
        "    with open(neg_file, \"rb\") as f:\n",
        "        for line in f:\n",
        "            rev = []\n",
        "            rev.append(line.strip())\n",
        "            if clean_string:\n",
        "                orig_rev =str(\" \".join(rev))\n",
        "            else:\n",
        "                orig_rev = \" \".join(rev).lower()\n",
        "            words = set(orig_rev.split())\n",
        "            for word in words:\n",
        "                vocab[word] += 1\n",
        "            datum = {\"y\": 0,\n",
        "                     \"text\": orig_rev,\n",
        "                     \"num_words\": len(orig_rev.split()),\n",
        "                     \"split\": np.random.randint(0, cv)}\n",
        "            revs.append(datum)\n",
        "    return revs, vocab\n",
        "\n",
        "## constructs word matrix from given word vector ##\n",
        "def get_W(word_vecs, k=32):\n",
        "    \"\"\"\n",
        "    Get word matrix. W[i] is the vector for word indexed by i\n",
        "    \"\"\"\n",
        "    word_idx_map = dict()\n",
        "    W = np.zeros(shape=(len(word_vecs) + 1, k), dtype='float32')\n",
        "    W[0] = np.zeros(k, dtype='float32')\n",
        "    i = 1\n",
        "    for word in word_vecs:\n",
        "        W[i] = word_vecs[word]\n",
        "        word_idx_map[word] = i\n",
        "        i += 1\n",
        "    return W, word_idx_map\n",
        "\n",
        "\n",
        "def load_bin_vec(fname, vocab):\n",
        "    \"\"\"\n",
        "    Loads 300x1 word vecs from Google (Mikolov) word2vec\n",
        "    \"\"\"\n",
        "    word_vecs = {}\n",
        "    with open(fname, \"rb\") as f:\n",
        "        header = f.readline()\n",
        "        vocab_size, layer1_size = map(int, header.split())\n",
        "        binary_len = np.dtype('float32').itemsize * layer1_size\n",
        "        for line in range(vocab_size):\n",
        "            word = []\n",
        "            while True:\n",
        "                ch = f.read(1)\n",
        "                if ch == ' ':\n",
        "                    word = ''.join(word)\n",
        "                    break\n",
        "                if ch != '\\n':\n",
        "                    word.append(ch)\n",
        "            if word in vocab:\n",
        "                word_vecs[word] = np.fromstring(f.read(binary_len), dtype='float32')\n",
        "            else:\n",
        "                f.read(binary_len)\n",
        "    return word_vecs\n",
        "\n",
        "\n",
        "def add_unknown_words(word_vecs, vocab, min_df=1, k=32):\n",
        "    \"\"\"\n",
        "    For words that occur in at least min_df documents, create a separate word vector.\n",
        "    0.25 is chosen so the unknown vectors have (approximately) same variance as pre-trained ones\n",
        "    \"\"\"\n",
        "    print(type(word_vecs))\n",
        "    for word in vocab:\n",
        "        if word not in word_vecs and vocab[word] >= min_df:\n",
        "            word_vecs[word] = np.random.uniform(-0.25, 0.25, k)\n",
        "\n",
        "\n",
        "\n",
        "def get_data(text_only):\n",
        "\n",
        "    if text_only:\n",
        "        print(\"Text only\")\n",
        "        image_list = []\n",
        "    else:\n",
        "        print(\"Text and image\")\n",
        "        image_list = read_image()\n",
        "\n",
        "    train_data = write_data(\"train\", image_list, text_only)\n",
        "    valiate_data = write_data(\"validate\", image_list, text_only)\n",
        "    test_data = write_data(\"test\", image_list, text_only)\n",
        "    print(len(train_data),\"***********\")\n",
        "    print(\"loading data...\")\n",
        "    vocab, all_text = Load_data(train_data, valiate_data, test_data)\n",
        "    print(\"len all_text\",str(len(all_text)))\n",
        "\n",
        "    print(\"number of sentences: \" + str(len(all_text)))\n",
        "    print(\"vocab size: \" + str(len(vocab)))\n",
        "    max_l = len(max(all_text, key=len))\n",
        "    print(\"max sentence length: \" + str(max_l))\n",
        "\n",
        "    file = open(\"/content/drive/MyDrive/WEIBO Dataset/w2v (1).pickle\", 'r')\n",
        "\n",
        "    # Read the content of the file\n",
        "    content = file.read()\n",
        "\n",
        "    # Close the file\n",
        "    file.close()\n",
        "\n",
        "    # Encode the content to UTF-8\n",
        "    w2v = content.encode(\"utf-8\")\n",
        "\n",
        "    print(type(w2v))\n",
        "\n",
        "    print(\"word2vec loaded!\")\n",
        "    print(\"num words already in word2vec: \" + str(len(w2v)))\n",
        "    W, word_idx_map = get_W(w2v)\n",
        "    rand_vecs = {}\n",
        "    add_unknown_words(rand_vecs, vocab)\n",
        "    W2 = rand_vecs = {}\n",
        "    w_file = open(\"/content/drive/MyDrive/WEIBO Dataset/EANN-KDD18-master/data/weibo/word_embedding.pickle\", \"wb\")\n",
        "    pickle.dump([W, W2, word_idx_map, vocab, max_l], w_file)\n",
        "    w_file.close()\n",
        "    return train_data, valiate_data, test_data\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iDSDSWLmdEEO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EANN: Event Adversarial Neural Network Model**\n"
      ],
      "metadata": {
        "id": "xXmp1SvveK-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import argparse\n",
        "import time, os\n",
        "import copy\n",
        "import pickle as pickle\n",
        "from random import sample\n",
        "import torchvision\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.optim.lr_scheduler import StepLR, MultiStepLR, ExponentialLR\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable, Function\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import scipy.io as sio"
      ],
      "metadata": {
        "id": "oYyl2TqneJ9g"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing Rumor Dataset"
      ],
      "metadata": {
        "id": "bzt_3oCH7Tim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Rumor_Data(Dataset):\n",
        "    def __init__(self, dataset):\n",
        "        self.text = torch.from_numpy(np.array(dataset['post_text']))\n",
        "        self.image = list(dataset['image'])\n",
        "        self.mask = torch.from_numpy(np.array(dataset['mask']))\n",
        "        self.label = torch.from_numpy(np.array(dataset['label']))\n",
        "        self.event_label = torch.from_numpy(np.array(dataset['event_label']))\n",
        "        print('TEXT: %d, Image: %d, labe: %d, Event: %d'\n",
        "               % (len(self.text), len(self.image), len(self.label), len(self.event_label)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.label)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.text[idx], self.image[idx], self.mask[idx]), self.label[idx], self.event_label[idx]\n"
      ],
      "metadata": {
        "id": "Tj8sr6CQeIob"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Gradient reversal for domain adaptation"
      ],
      "metadata": {
        "id": "6suW6KFJ7fZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReverseLayerF(Function):\n",
        "    def forward(ctx, x, lambd):\n",
        "        # Save lambd for use in backward pass\n",
        "        ctx.lambd = lambd\n",
        "        return x.view_as(x)\n",
        "\n",
        "    def backward(ctx, grad_output):\n",
        "        # Retrieve lambd from the context\n",
        "        lambd = ctx.lambd\n",
        "        # Scale the gradient by -lambd\n",
        "        return (grad_output * -lambd), None\n",
        "\n",
        "def grad_reverse(x, lambd):\n",
        "    return ReverseLayerF.apply(x, lambd)"
      ],
      "metadata": {
        "id": "VhkbvWGWehI5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text data is processed using an embedding layer and a convolutional neural network (CNN), while the image data is processed through a pre-trained VGG19 network."
      ],
      "metadata": {
        "id": "nDtffszY7qA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural Network Model (1 hidden layer)\n",
        "class CNN_Fusion(nn.Module):\n",
        "    # def __init__(self, args, W):\n",
        "    def __init__(self, args):\n",
        "        super(CNN_Fusion, self).__init__()\n",
        "        self.args = args\n",
        "\n",
        "        self.event_num = args.event_num\n",
        "\n",
        "        vocab_size = args.vocab_size\n",
        "        emb_dim = args.embed_dim\n",
        "\n",
        "        C = args.class_num\n",
        "        self.hidden_size = args.hidden_dim\n",
        "        self.lstm_size = args.embed_dim\n",
        "        self.social_size = 19\n",
        "\n",
        "        # TEXT RNN\n",
        "        self.embed = nn.Embedding(vocab_size, emb_dim)\n",
        "        # self.embed.weight = nn.Parameter(torch.from_numpy(W))\n",
        "        self.lstm = nn.LSTM(self.lstm_size, self.lstm_size)\n",
        "        self.text_fc = nn.Linear(self.lstm_size, self.hidden_size)\n",
        "        self.text_encoder = nn.Linear(emb_dim, self.hidden_size)\n",
        "\n",
        "        ### TEXT CNN\n",
        "        channel_in = 1\n",
        "        filter_num = 20\n",
        "        window_size = [1, 2, 3, 4]\n",
        "        self.convs = nn.ModuleList([nn.Conv2d(channel_in, filter_num, (K, emb_dim)) for K in window_size])\n",
        "        self.fc1 = nn.Linear(len(window_size) * filter_num, self.hidden_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(args.dropout)\n",
        "\n",
        "        #IMAGE\n",
        "        #hidden_size = args.hidden_dim\n",
        "        vgg_19 = torchvision.models.vgg19(pretrained=True)\n",
        "        for param in vgg_19.parameters():\n",
        "            param.requires_grad = False\n",
        "        # visual model\n",
        "        num_ftrs = vgg_19.classifier._modules['6'].out_features\n",
        "        self.vgg = vgg_19\n",
        "        self.image_fc1 = nn.Linear(num_ftrs,  self.hidden_size)\n",
        "        #self.image_fc2 = nn.Linear(512, self.hidden_size)\n",
        "        self.image_adv = nn.Linear(self.hidden_size,  int(self.hidden_size))\n",
        "        self.image_encoder = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "\n",
        "        ###social context\n",
        "        self.social = nn.Linear(self.social_size, self.hidden_size)\n",
        "\n",
        "        ##ATTENTION\n",
        "        self.attention_layer = nn.Linear(self.hidden_size, emb_dim)\n",
        "\n",
        "        ## Class  Classifier\n",
        "        self.class_classifier = nn.Sequential()\n",
        "        self.class_classifier.add_module('c_fc1', nn.Linear(2 * self.hidden_size, 2))\n",
        "        self.class_classifier.add_module('c_softmax', nn.Softmax(dim=1))\n",
        "\n",
        "        ###Event Classifier\n",
        "        self.domain_classifier = nn.Sequential()\n",
        "        self.domain_classifier.add_module('d_fc1', nn.Linear(2 * self.hidden_size, self.hidden_size))\n",
        "        #self.domain_classifier.add_module('d_bn1', nn.BatchNorm2d(self.hidden_size))\n",
        "        self.domain_classifier.add_module('d_relu1', nn.LeakyReLU(True))\n",
        "        self.domain_classifier.add_module('d_fc2', nn.Linear(self.hidden_size, self.event_num))\n",
        "        self.domain_classifier.add_module('d_softmax', nn.Softmax(dim=1))\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        # Before we've done anything, we dont have any hidden state.\n",
        "        # Refer to the Pytorch documentation to see exactly\n",
        "        # why they have this dimensionality.\n",
        "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
        "        return (to_var(torch.zeros(1, batch_size, self.lstm_size)),\n",
        "                to_var(torch.zeros(1, batch_size, self.lstm_size)))\n",
        "\n",
        "    def conv_and_pool(self, x, conv):\n",
        "        x = F.relu(conv(x)).squeeze(3)  # (sample number,hidden_dim, length)\n",
        "        x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, text, image,  mask):\n",
        "        ### IMAGE #####\n",
        "        image = self.vgg(image) #[N, 512]\n",
        "        image = F.leaky_relu(self.image_fc1(image))\n",
        "\n",
        "        ##########CNN##################\n",
        "        text = self.embed(text)\n",
        "        text = text * mask.unsqueeze(2).expand_as(text)\n",
        "        text = text.unsqueeze(1)\n",
        "        text = [F.leaky_relu(conv(text)).squeeze(3) for conv in self.convs]  # [(N,hidden_dim,W), ...]*len(window_size)\n",
        "        text = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in text]\n",
        "        text = torch.cat(text, 1)\n",
        "        text = F.leaky_relu(self.fc1(text))\n",
        "        text_image = torch.cat((text, image), 1)\n",
        "\n",
        "        ### Fake or real\n",
        "        class_output = self.class_classifier(text_image)\n",
        "        ## Domain (which Event )\n",
        "        lambd=0.5\n",
        "        reverse_feature = grad_reverse(text_image,lambd)\n",
        "        domain_output = self.domain_classifier(reverse_feature)\n",
        "        return class_output, domain_output"
      ],
      "metadata": {
        "id": "CNISUCzreo-J"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling PyTorch tensors, variable conversions, data splitting, and class weighting calculation"
      ],
      "metadata": {
        "id": "_JO15qQc7zDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_var(x):\n",
        "    if torch.cuda.is_available():\n",
        "        x = x.cuda()\n",
        "    return Variable(x)\n",
        "\n",
        "\n",
        "def to_np(x):\n",
        "    return x.data.cpu().numpy()\n",
        "\n",
        "def select(train, selec_indices):\n",
        "    temp = []\n",
        "    for i in range(len(train)):\n",
        "        print(\"length is \"+str(len(train[i])))\n",
        "        print(i)\n",
        "        ele = list(train[i])\n",
        "        temp.append([ele[i] for i in selec_indices])\n",
        "    return temp\n",
        "\n",
        "def make_weights_for_balanced_classes(event, nclasses = 15):\n",
        "    count = [0] * nclasses\n",
        "    for item in event:\n",
        "        count[item] += 1\n",
        "    weight_per_class = [0.] * nclasses\n",
        "    N = float(sum(count))\n",
        "    for i in range(nclasses):\n",
        "        weight_per_class[i] = N/float(count[i])\n",
        "    weight = [0] * len(event)\n",
        "    for idx, val in enumerate(event):\n",
        "        weight[idx] = weight_per_class[val]\n",
        "    return weight\n",
        "\n",
        "def split_train_validation(train, percent):\n",
        "    whole_len = len(train[0])\n",
        "\n",
        "    train_indices = (sample(range(whole_len), int(whole_len * percent)))\n",
        "    train_data = select(train, train_indices)\n",
        "    print(\"train data size is \"+ str(len(train[3])))\n",
        "\n",
        "    validation = select(train, np.delete(range(len(train[0])), train_indices))\n",
        "    print(\"validation size is \"+ str(len(validation[3])))\n",
        "    print(\"train and validation data set has been splited\")\n",
        "\n",
        "\n",
        "    return train_data, validation"
      ],
      "metadata": {
        "id": "xkveUG8le4xG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main thread and evaluation loop"
      ],
      "metadata": {
        "id": "VAGcPP_r76vq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main(args):\n",
        "    print('loading data')\n",
        "    train, validation, test = load_data(args)\n",
        "\n",
        "    test_id = test['post_id']\n",
        "    train_dataset = Rumor_Data(train)\n",
        "\n",
        "    validate_dataset = Rumor_Data(validation)\n",
        "\n",
        "    test_dataset = Rumor_Data(test)\n",
        "\n",
        "    # Data Loader (Input Pipeline)\n",
        "    train_loader = DataLoader(dataset=train_dataset,\n",
        "                              batch_size=args.batch_size,\n",
        "                              shuffle=True)\n",
        "\n",
        "    validate_loader = DataLoader(dataset = validate_dataset,\n",
        "                                 batch_size=args.batch_size,\n",
        "                                 shuffle=False)\n",
        "\n",
        "    test_loader = DataLoader(dataset=test_dataset,\n",
        "                             batch_size=args.batch_size,\n",
        "                             shuffle=False)\n",
        "\n",
        "    print('building model')\n",
        "    model = CNN_Fusion(args)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"CUDA\")\n",
        "        model.cuda()\n",
        "\n",
        "    # Loss and Optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, list(model.parameters())),\n",
        "                                 lr= args.learning_rate)\n",
        "\n",
        "    iter_per_epoch = len(train_loader)\n",
        "    print(\"loader size \" + str(len(train_loader)))\n",
        "    best_validate_acc = 0.000\n",
        "    best_test_acc = 0.000\n",
        "    best_loss = 100\n",
        "    best_validate_dir = ''\n",
        "    best_list = [0,0]\n",
        "\n",
        "    print('training model')\n",
        "    adversarial = True\n",
        "    # Train the Model\n",
        "    for epoch in range(args.num_epochs):\n",
        "\n",
        "        p = float(epoch) / 100\n",
        "        #lambd = 2. / (1. + np.exp(-10. * p)) - 1\n",
        "        lr = 0.001 / (1. + 10 * p) ** 0.75\n",
        "\n",
        "        optimizer.lr = lr\n",
        "        #rgs.lambd = lambd\n",
        "        start_time = time.time()\n",
        "        cost_vector = []\n",
        "        class_cost_vector = []\n",
        "        domain_cost_vector = []\n",
        "        acc_vector = []\n",
        "        valid_acc_vector = []\n",
        "        test_acc_vector = []\n",
        "        vali_cost_vector = []\n",
        "        test_cost_vector = []\n",
        "\n",
        "        for i, (train_data, train_labels, event_labels) in enumerate(train_loader):\n",
        "            train_text, train_image,  train_mask, train_labels, event_labels = \\\n",
        "                to_var(train_data[0]), to_var(train_data[1]), to_var(train_data[2]), \\\n",
        "                to_var(train_labels), to_var(event_labels)\n",
        "\n",
        "            # Forward + Backward + Optimize\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            class_outputs, domain_outputs = model(train_text, train_image, train_mask)\n",
        "\n",
        "            ## Fake or Real loss\n",
        "            class_loss = criterion(class_outputs, train_labels)\n",
        "            # Event Loss\n",
        "            domain_loss = criterion(domain_outputs, event_labels)\n",
        "            loss = class_loss + domain_loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            _, argmax = torch.max(class_outputs, 1)\n",
        "\n",
        "            cross_entropy = True\n",
        "\n",
        "            if True:\n",
        "                accuracy = (train_labels == argmax.squeeze()).float().mean()\n",
        "            else:\n",
        "                _, labels = torch.max(train_labels, 1)\n",
        "                accuracy = (labels.squeeze() == argmax.squeeze()).float().mean()\n",
        "            class_cost_vector.append(class_loss.item())\n",
        "            domain_cost_vector.append(domain_loss.item())\n",
        "            cost_vector.append(loss.item())\n",
        "            acc_vector.append(accuracy.item())\n",
        "\n",
        "        model.eval()\n",
        "        validate_acc_vector_temp = []\n",
        "        for i, (validate_data, validate_labels, event_labels) in enumerate(validate_loader):\n",
        "            validate_text, validate_image,  validate_mask, validate_labels, event_labels = \\\n",
        "                to_var(validate_data[0]), to_var(validate_data[1]), to_var(validate_data[2]), \\\n",
        "                to_var(validate_labels), to_var(event_labels)\n",
        "            validate_outputs, domain_outputs = model(validate_text, validate_image, validate_mask)\n",
        "            _, validate_argmax = torch.max(validate_outputs, 1)\n",
        "            vali_loss = criterion(validate_outputs, validate_labels)\n",
        "\n",
        "            validate_accuracy = (validate_labels == validate_argmax.squeeze()).float().mean()\n",
        "            vali_cost_vector.append( vali_loss.item())\n",
        "            validate_acc_vector_temp.append(validate_accuracy.item())\n",
        "        validate_acc = np.mean(validate_acc_vector_temp)\n",
        "        valid_acc_vector.append(validate_acc)\n",
        "        model.train()\n",
        "        print ('Epoch [%d/%d],  Loss: %.4f, Class Loss: %.4f, domain loss: %.4f, Train_Acc: %.4f,  Validate_Acc: %.4f.'\n",
        "                % (\n",
        "                epoch + 1, args.num_epochs,  np.mean(cost_vector), np.mean(class_cost_vector),  np.mean(domain_cost_vector),\n",
        "                    np.mean(acc_vector),   validate_acc))\n",
        "\n",
        "        if validate_acc > best_validate_acc:\n",
        "            best_validate_acc = validate_acc\n",
        "            if not os.path.exists(args.output_file):\n",
        "                os.mkdir(args.output_file)\n",
        "\n",
        "            best_validate_dir = args.output_file + str(epoch + 1) + '.pkl'\n",
        "            torch.save(model.state_dict(), best_validate_dir)\n",
        "\n",
        "        duration = time.time() - start_time\n",
        "\n",
        "    print('testing model')\n",
        "    model = CNN_Fusion(args)\n",
        "    model.load_state_dict(torch.load(best_validate_dir))\n",
        "    if torch.cuda.is_available():\n",
        "        model.cuda()\n",
        "    model.eval()\n",
        "    test_score = []\n",
        "    test_pred = []\n",
        "    test_true = []\n",
        "    for i, (test_data, test_labels, event_labels) in enumerate(test_loader):\n",
        "        test_text, test_image, test_mask, test_labels = to_var(\n",
        "            test_data[0]), to_var(test_data[1]), to_var(test_data[2]), to_var(test_labels)\n",
        "        test_outputs, domain_outputs= model(test_text, test_image, test_mask)\n",
        "        _, test_argmax = torch.max(test_outputs, 1)\n",
        "        if i == 0:\n",
        "            test_score = to_np(test_outputs.squeeze())\n",
        "            test_pred = to_np(test_argmax.squeeze())\n",
        "            test_true = to_np(test_labels.squeeze())\n",
        "        else:\n",
        "            test_score = np.concatenate((test_score, to_np(test_outputs.squeeze())), axis=0)\n",
        "            test_pred = np.concatenate((test_pred, to_np(test_argmax.squeeze())), axis=0)\n",
        "            test_true = np.concatenate((test_true, to_np(test_labels.squeeze())), axis=0)\n",
        "\n",
        "    test_accuracy = metrics.accuracy_score(test_true, test_pred)\n",
        "    test_f1 = metrics.f1_score(test_true, test_pred, average='macro')\n",
        "    test_precision = metrics.precision_score(test_true, test_pred, average='macro')\n",
        "    test_recall = metrics.recall_score(test_true, test_pred, average='macro')\n",
        "    test_score_convert = [x[1] for x in test_score]\n",
        "    test_aucroc = metrics.roc_auc_score(test_true, test_score_convert, average='macro')\n",
        "\n",
        "    test_confusion_matrix = metrics.confusion_matrix(test_true, test_pred)\n",
        "\n",
        "    print(\"Classification Acc: %.4f, AUC-ROC: %.4f\"\n",
        "          % (test_accuracy, test_aucroc))\n",
        "    print(\"Classification report:\\n%s\\n\"\n",
        "          % (metrics.classification_report(test_true, test_pred)))\n",
        "    print(\"Classification confusion matrix:\\n%s\\n\"\n",
        "          % (test_confusion_matrix))\n",
        "    classes = ('Non rumor','Rumor')\n",
        "    df_cm = pd.DataFrame(test_confusion_matrix.astype('float')/test_confusion_matrix.sum(axis=1)[:, np.newaxis], index = [i for i in classes],\n",
        "                     columns = [i for i in classes])\n",
        "    plt.figure(figsize = (12,7))\n",
        "    sn.heatmap(df_cm, annot=True)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.savefig('output.png')\n"
      ],
      "metadata": {
        "id": "9lRcNh0He_mD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining and parsing command-line arguments for training and testing"
      ],
      "metadata": {
        "id": "XndKXPOM8GJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_arguments(parser):\n",
        "    parser.add_argument('training_file', type=str, metavar='<training_file>', help='')\n",
        "    parser.add_argument('testing_file', type=str, metavar='<testing_file>', help='')\n",
        "    parser.add_argument('output_file', type=str, metavar='<output_file>', help='')\n",
        "\n",
        "    parse.add_argument('--static', type=bool, default=True, help='')\n",
        "    parser.add_argument('--sequence_length', type=int, default=28, help='')\n",
        "    parser.add_argument('--class_num', type=int, default=2, help='')\n",
        "    parser.add_argument('--hidden_dim', type=int, default = 32, help='')\n",
        "    parser.add_argument('--embed_dim', type=int, default=32, help='')\n",
        "    parser.add_argument('--vocab_size', type=int, default=300, help='')\n",
        "    parser.add_argument('--dropout', type=int, default=0.5, help='')\n",
        "    parser.add_argument('--filter_num', type=int, default=5, help='')\n",
        "    parser.add_argument('--lambd', type=int, default= 1, help='')\n",
        "    parser.add_argument('--text_only', type=bool, default= False, help='')\n",
        "\n",
        "\n",
        "    parser.add_argument('--d_iter', type=int, default=3, help='')\n",
        "    parser.add_argument('--batch_size', type=int, default=100, help='')\n",
        "    parser.add_argument('--num_epochs', type=int, default=10, help='')\n",
        "    parser.add_argument('--learning_rate', type=float, default=0.001, help='')\n",
        "    parser.add_argument('--event_num', type=int, default=10, help='')\n",
        "\n",
        "    return parser"
      ],
      "metadata": {
        "id": "jMjsssMBf1V6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Returns the top posts based on predicted probabilities and labels"
      ],
      "metadata": {
        "id": "7PDOHxnx8P0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_post(output, label, test_id, top_n = 500):\n",
        "    filter_output = []\n",
        "    filter_id = []\n",
        "\n",
        "    for i, l in enumerate(label):\n",
        "        if np.argmax(output[i]) == l and int(l) == 1 :\n",
        "            filter_output.append(output[i][1])\n",
        "            filter_id.append(test_id[i])\n",
        "\n",
        "    filter_output = np.array(filter_output)\n",
        "\n",
        "    top_n_indice = filter_output.argsort()[-top_n:][::-1]\n",
        "\n",
        "    top_n_id = np.array(filter_id)[top_n_indice]\n",
        "    top_n_id_dict = {}\n",
        "    for i in top_n_id:\n",
        "        top_n_id_dict[i] = True\n",
        "\n",
        "    pickle.dump(top_n_id_dict, open(\"../Data/weibo/top_n_id.pickle\", \"wb\"))\n",
        "\n",
        "    return top_n_id"
      ],
      "metadata": {
        "id": "PK7WN7CNgJdW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating word embeddings for posts and creates masks for padding"
      ],
      "metadata": {
        "id": "vdsKRqk28U62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word2vec(post, word_id_map, W):\n",
        "    word_embedding = []\n",
        "    mask = []\n",
        "    unknown_word_id = len(word_id_map)  # Assign a unique ID greater than the maximum ID in your vocabulary\n",
        "\n",
        "    for sentence in post:\n",
        "        sen_embedding = []\n",
        "        mask_seq = np.zeros(args.sequence_len, dtype=np.float32)\n",
        "        mask_seq[:len(sentence)] = 1.0\n",
        "\n",
        "        for word in sentence:\n",
        "            if word in word_id_map:\n",
        "                sen_embedding.append(word_id_map[word])\n",
        "            else:\n",
        "                # Handle out-of-vocabulary words\n",
        "                # For example, you can assign a special ID for unknown words\n",
        "                sen_embedding.append(unknown_word_id)\n",
        "\n",
        "        # Pad the sentence embedding if its length is less than args.sequence_len\n",
        "        while len(sen_embedding) < args.sequence_len:\n",
        "            sen_embedding.append(0)  # Padding token ID\n",
        "\n",
        "        word_embedding.append(copy.deepcopy(sen_embedding))\n",
        "        mask.append(copy.deepcopy(mask_seq))\n",
        "\n",
        "    return word_embedding, mask\n"
      ],
      "metadata": {
        "id": "Vf14OLXDgvFj"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading and preprocessing the data for training, validation, and testing. Applying word embedding and creates masks for padding."
      ],
      "metadata": {
        "id": "CkD4ZUuU8aSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(args):\n",
        "    train, validate, test = get_data(args.text_only)\n",
        "    word_vector_path = '/content/drive/MyDrive/WEIBO Dataset/EANN-KDD18-master/data/weibo/word_embedding.pickle'\n",
        "    f = open(word_vector_path, 'rb')\n",
        "    weight = pickle.loads(f.read())  # W, W2, word_idx_map, vocab\n",
        "\n",
        "\n",
        "    W, W2, word_idx_map, vocab, max_len = weight[0], weight[1], weight[2], weight[3], weight[4]\n",
        "    args.vocab_size = len(vocab)\n",
        "    args.sequence_len = max_len\n",
        "    print(\"translate data to embedding\")\n",
        "\n",
        "    word_embedding, mask = word2vec(validate['post_text'], word_idx_map, W)\n",
        "    validate['post_text'] = word_embedding\n",
        "    validate['mask'] = mask\n",
        "\n",
        "\n",
        "    print(\"translate test data to embedding\")\n",
        "    word_embedding, mask = word2vec(test['post_text'], word_idx_map, W)\n",
        "    test['post_text'] = word_embedding\n",
        "    test['mask']=mask\n",
        "    word_embedding, mask = word2vec(train['post_text'], word_idx_map, W)\n",
        "    train['post_text'] = word_embedding\n",
        "    train['mask'] = mask\n",
        "    print(\"sequence length \" + str(args.sequence_length))\n",
        "    print(\"Train Data Size is \"+str(len(train['post_text'])))\n",
        "    print(\"Finished loading data \")\n",
        "    return train, validate, test\n",
        "\n",
        "def transform(event):\n",
        "    matrix = np.zeros([len(event), max(event) + 1])\n",
        "    for i, l in enumerate(event):\n",
        "        matrix[i, l] = 1.00\n",
        "    return matrix\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parse = argparse.ArgumentParser()\n",
        "    parser = parse_arguments(parse)\n",
        "    train = ''\n",
        "    test = ''\n",
        "    output = '/content/drive/MyDrive/WEIBO Dataset/EANN-KDD18-master/data/weiboRESULT/'\n",
        "    args = parser.parse_args([train, test, output])\n",
        "\n",
        "    main(args)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7J2TyhsngvxK",
        "outputId": "8b956583-27c3-4b59-93a5-d602dd6981ab"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data\n",
            "Text and image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "DEBUG:jieba:Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "DEBUG:jieba:Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.952 seconds.\n",
            "DEBUG:jieba:Loading model cost 0.952 seconds.\n",
            "Prefix dict has been built successfully.\n",
            "DEBUG:jieba:Prefix dict has been built successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original post length is 2329\n",
            "Original data frame is (2329, 6)\n",
            "Label number is 43\n",
            "Rummor number is 15\n",
            "Non rummor is 28\n",
            "data size is 43\n",
            "paired post length is 43\n",
            "paried data has 8 dimension\n",
            "Original post length is 340\n",
            "Original data frame is (340, 6)\n",
            "Label number is 11\n",
            "Rummor number is 7\n",
            "Non rummor is 4\n",
            "data size is 11\n",
            "paired post length is 11\n",
            "paried data has 8 dimension\n",
            "Original post length is 686\n",
            "Original data frame is (686, 6)\n",
            "Label number is 20\n",
            "Rummor number is 5\n",
            "Non rummor is 15\n",
            "data size is 20\n",
            "paired post length is 20\n",
            "paried data has 8 dimension\n",
            "8 ***********\n",
            "loading data...\n",
            "74 *************\n",
            "len all_text 74\n",
            "number of sentences: 74\n",
            "vocab size: 1307\n",
            "max sentence length: 255\n",
            "<class 'bytes'>\n",
            "word2vec loaded!\n",
            "num words already in word2vec: 1907002\n",
            "<class 'dict'>\n",
            "translate data to embedding\n",
            "translate test data to embedding\n",
            "sequence length 28\n",
            "Train Data Size is 43\n",
            "Finished loading data \n",
            "TEXT: 43, Image: 43, labe: 43, Event: 43\n",
            "TEXT: 11, Image: 11, labe: 11, Event: 11\n",
            "TEXT: 20, Image: 20, labe: 20, Event: 20\n",
            "building model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
            "100%|██████████| 548M/548M [00:07<00:00, 77.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loader size 1\n",
            "training model\n",
            "Epoch [1/10],  Loss: 2.9716, Class Loss: 0.6632, domain loss: 2.3084, Train_Acc: 0.6279,  Validate_Acc: 0.3636.\n",
            "Epoch [2/10],  Loss: 2.9126, Class Loss: 0.5990, domain loss: 2.3137, Train_Acc: 0.7209,  Validate_Acc: 0.3636.\n",
            "Epoch [3/10],  Loss: 2.8743, Class Loss: 0.5613, domain loss: 2.3130, Train_Acc: 0.7674,  Validate_Acc: 0.6364.\n",
            "Epoch [4/10],  Loss: 2.8394, Class Loss: 0.5266, domain loss: 2.3128, Train_Acc: 0.7907,  Validate_Acc: 0.7273.\n",
            "Epoch [5/10],  Loss: 2.8122, Class Loss: 0.4957, domain loss: 2.3165, Train_Acc: 0.8140,  Validate_Acc: 0.7273.\n",
            "Epoch [6/10],  Loss: 2.8031, Class Loss: 0.4824, domain loss: 2.3207, Train_Acc: 0.8140,  Validate_Acc: 0.7273.\n",
            "Epoch [7/10],  Loss: 2.8011, Class Loss: 0.4790, domain loss: 2.3221, Train_Acc: 0.8372,  Validate_Acc: 0.7273.\n",
            "Epoch [8/10],  Loss: 2.7625, Class Loss: 0.4450, domain loss: 2.3174, Train_Acc: 0.8605,  Validate_Acc: 0.6364.\n",
            "Epoch [9/10],  Loss: 2.7595, Class Loss: 0.4358, domain loss: 2.3237, Train_Acc: 0.9070,  Validate_Acc: 0.6364.\n",
            "Epoch [10/10],  Loss: 2.7673, Class Loss: 0.4399, domain loss: 2.3275, Train_Acc: 0.9070,  Validate_Acc: 0.6364.\n",
            "testing model\n",
            "Classification Acc: 0.5000, AUC-ROC: 0.1600\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.67      0.67        15\n",
            "           1       0.00      0.00      0.00         5\n",
            "\n",
            "    accuracy                           0.50        20\n",
            "   macro avg       0.33      0.33      0.33        20\n",
            "weighted avg       0.50      0.50      0.50        20\n",
            "\n",
            "\n",
            "Classification confusion matrix:\n",
            "[[10  5]\n",
            " [ 5  0]]\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x700 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}